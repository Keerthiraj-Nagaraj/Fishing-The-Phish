{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data manipulation and analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GRU, SimpleRNN\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit learn \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Misc\n",
    "from six.moves import cPickle\n",
    "import pickle\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_functions import plot_history\n",
    "from my_functions import clean_text\n",
    "from my_functions import avg_word_len\n",
    "#from my_functions import perf_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "[lib,con,neutral]= pickle.load(open('ibcData.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberal = []\n",
    "for tree in lib:\n",
    "    liberal.append(tree.get_words())\n",
    "conservative = []\n",
    "for tree in con:\n",
    "    conservative.append(tree.get_words())\n",
    "neu = []\n",
    "for tree in neutral:\n",
    "    neu.append(tree.get_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "liberals = pd.DataFrame(liberal,columns=['text'])\n",
    "liberals['label'] = 0\n",
    "conservatives = pd.DataFrame(conservative,columns=['text'])\n",
    "conservatives['label'] = 1\n",
    "neutrals = pd.DataFrame(neu,columns=['text'])\n",
    "neutrals['label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [liberals,conservatives]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['text'] = result['text'].map(lambda x: clean_text(x))\n",
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "my_ibc_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 85487)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['word_count'] = my_ibc_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_ibc_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 628655)\n"
     ]
    }
   ],
   "source": [
    "my_ibc_data['char_count'] = my_ibc_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_ibc_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nation destroyed war also destroyed political ...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>128</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>efficiency term tax system limit risk corporat...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>136</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  word_count  \\\n",
       "0  nation destroyed war also destroyed political ...      1          17   \n",
       "1  efficiency term tax system limit risk corporat...      0          18   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0         128                6  \n",
       "1         136                6  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ibc_data['avg_word_length'] = my_ibc_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_ibc_data['avg_word_length'].values)/len(my_ibc_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_ibc_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  22.943370907139023\n",
      "median:  22.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_ibc_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files_path = 'data_stage_one/training_set/*.txt'\n",
    "convote_test_files_path = 'data_stage_one/test_set/*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_train_files = glob.glob(convote_train_files_path)\n",
    "convote_test_files = glob.glob(convote_test_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'convote_train': convote_train_files,\n",
    "                 'convote_test': convote_test_files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = []\n",
    "\n",
    "for data_type, filenames in filepath_dict.items():\n",
    "    for i in range(len(filenames)):\n",
    "        f = open(filenames[i], 'r')\n",
    "        f_text = f.read()\n",
    "        f.close()\n",
    "        party = filenames[i].split('_')[-1][0]\n",
    "        sample_group = data_type.split('_')[-1]\n",
    "        review_label = 0 if party == 'D' else 1\n",
    "        convote_data.append([f_text, party, sample_group, review_label])\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = pd.DataFrame(convote_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data = convote_data.rename(index=str, columns={0: 'text', 1: 'party', 2: 'group', 3: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_data['text'] = convote_data['text'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_convote_data = pd.DataFrame(convote_data.iloc[:,[0,3]].values)\n",
    "my_convote_data = my_convote_data.rename(index=str, columns={0: 'text', 1: 'party_label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall word count', 1016800)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['word_count'] = my_convote_data['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "overall_word_count = np.sum(my_convote_data['word_count'].values)\n",
    "print(\"Overall word count\", overall_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall char count', 7330698)\n"
     ]
    }
   ],
   "source": [
    "my_convote_data['char_count'] = my_convote_data['text'].str.len()\n",
    "overall_char_count = np.sum(my_convote_data['char_count'].values)\n",
    "print(\"Overall char count\", overall_char_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Overall average word length', 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>party_label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr speaker rise join many colleague strongly o...</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>3901</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr chairman rise support amendment two ground ...</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>811</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text party_label  word_count  \\\n",
       "0  mr speaker rise join many colleague strongly o...           0         540   \n",
       "1  mr chairman rise support amendment two ground ...           0         114   \n",
       "\n",
       "   char_count  avg_word_length  \n",
       "0        3901                6  \n",
       "1         811                6  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_convote_data['avg_word_length'] = my_convote_data['text'].apply(lambda x: avg_word_len(x))\n",
    "overall_word_avg_len = np.sum(my_convote_data['avg_word_length'].values)/len(my_convote_data['avg_word_length'].values)\n",
    "print(\"Overall average word length\", overall_word_avg_len)\n",
    "my_convote_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word count per sentence\n",
      "mean:  137.0535112548861\n",
      "median:  42.0\n"
     ]
    }
   ],
   "source": [
    "word_count_each_sentence = np.array(my_convote_data['word_count'].values)\n",
    "print 'word count per sentence'\n",
    "print 'mean: ', np.mean(word_count_each_sentence)\n",
    "print 'median: ', np.median(word_count_each_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc = pd.DataFrame(my_ibc_data.iloc[:,[0,1]].values)\n",
    "convote = pd.DataFrame(my_convote_data.iloc[:,[0,1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_data = [ibc, convote]\n",
    "overall_data = pd.concat(overall_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_text = np.array(my_ibc_data.iloc[:,0].values)\n",
    "ibc_labels = np.array(my_ibc_data.iloc[:,1].values)\n",
    "\n",
    "convote_text = np.array(my_convote_data.iloc[:,0].values)\n",
    "convote_labels = np.array(my_convote_data.iloc[:,1].values)\n",
    "\n",
    "overall_text = np.array(overall_data.iloc[:,0].values)\n",
    "overall_labels = np.array(overall_data.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count = 50000\n",
    "seq_length = 20 #Number of items in each sequence\n",
    "\n",
    "tokenizer = Tokenizer(num_words=total_word_count)\n",
    "tokenizer.fit_on_texts(convote_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibc_sequences = tokenizer.texts_to_sequences(ibc_text)\n",
    "ibc_sequences = pad_sequences(ibc_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "convote_sequences = tokenizer.texts_to_sequences(convote_text)\n",
    "convote_sequences = pad_sequences(convote_sequences, maxlen=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_5_data = ibc_sequences\n",
    "exp_5_labels = ibc_labels\n",
    "\n",
    "add_data = convote_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 7 - semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_5_data, exp_5_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.7604 - acc: 0.4560 - val_loss: 0.6931 - val_acc: 0.5034\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.6907 - acc: 0.5321 - val_loss: 0.6958 - val_acc: 0.4966\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.6890 - acc: 0.5444 - val_loss: 0.6978 - val_acc: 0.4966\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.6682 - acc: 0.6204 - val_loss: 0.6720 - val_acc: 0.5940\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.5684 - acc: 0.8031 - val_loss: 0.6763 - val_acc: 0.5805\n",
      "Epoch 6/10\n",
      " - 3s - loss: 0.4610 - acc: 0.8788 - val_loss: 0.6975 - val_acc: 0.5906\n",
      "Epoch 7/10\n",
      " - 3s - loss: 0.3659 - acc: 0.9157 - val_loss: 0.7277 - val_acc: 0.5839\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_7_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6287\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9359 samples, validate on 1040 samples\n",
      "Epoch 1/10\n",
      " - 14s - loss: 0.4597 - acc: 0.8538 - val_loss: 0.3188 - val_acc: 0.9163\n",
      "Epoch 2/10\n",
      " - 12s - loss: 0.3034 - acc: 0.9133 - val_loss: 0.3109 - val_acc: 0.8990\n",
      "Epoch 3/10\n",
      " - 12s - loss: 0.2343 - acc: 0.9350 - val_loss: 0.2876 - val_acc: 0.8952\n",
      "Epoch 4/10\n",
      " - 12s - loss: 0.1976 - acc: 0.9442 - val_loss: 0.3147 - val_acc: 0.8875\n",
      "Epoch 5/10\n",
      " - 12s - loss: 0.1649 - acc: 0.9560 - val_loss: 0.3113 - val_acc: 0.8875\n",
      "Epoch 6/10\n",
      " - 12s - loss: 0.1433 - acc: 0.9625 - val_loss: 0.3478 - val_acc: 0.8740\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6501\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/10\n",
      " - 5s - loss: 0.6893 - acc: 0.5440 - val_loss: 0.6982 - val_acc: 0.4966\n",
      "Epoch 2/10\n",
      " - 3s - loss: 0.6743 - acc: 0.5697 - val_loss: 0.6727 - val_acc: 0.5839\n",
      "Epoch 3/10\n",
      " - 3s - loss: 0.5492 - acc: 0.7625 - val_loss: 0.6809 - val_acc: 0.5772\n",
      "Epoch 4/10\n",
      " - 3s - loss: 0.4087 - acc: 0.8482 - val_loss: 0.7410 - val_acc: 0.5973\n",
      "Epoch 5/10\n",
      " - 3s - loss: 0.2995 - acc: 0.9057 - val_loss: 0.7914 - val_acc: 0.5839\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_7_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6153\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9359 samples, validate on 1040 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.4341 - acc: 0.8216 - val_loss: 0.3030 - val_acc: 0.8837\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.2979 - acc: 0.8855 - val_loss: 0.2959 - val_acc: 0.8635\n",
      "Epoch 3/10\n",
      " - 11s - loss: 0.2262 - acc: 0.9214 - val_loss: 0.2916 - val_acc: 0.8721\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.1854 - acc: 0.9355 - val_loss: 0.2719 - val_acc: 0.8846\n",
      "Epoch 5/10\n",
      " - 11s - loss: 0.1535 - acc: 0.9499 - val_loss: 0.2939 - val_acc: 0.8865\n",
      "Epoch 6/10\n",
      " - 11s - loss: 0.1324 - acc: 0.9603 - val_loss: 0.3361 - val_acc: 0.8683\n",
      "Epoch 7/10\n",
      " - 11s - loss: 0.1117 - acc: 0.9668 - val_loss: 0.3611 - val_acc: 0.8692\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6113\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2682 samples, validate on 298 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 0.7651 - acc: 0.4571 - val_loss: 0.6994 - val_acc: 0.5034\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.7019 - acc: 0.4948 - val_loss: 0.6947 - val_acc: 0.4899\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.6936 - acc: 0.5153 - val_loss: 0.6982 - val_acc: 0.4966\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.6812 - acc: 0.5652 - val_loss: 0.6989 - val_acc: 0.4966\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.6769 - acc: 0.5824 - val_loss: 0.6976 - val_acc: 0.4933\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.6676 - acc: 0.5984 - val_loss: 0.7001 - val_acc: 0.5101\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.6500 - acc: 0.6421 - val_loss: 0.7001 - val_acc: 0.4966\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_7_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5576\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9359 samples, validate on 1040 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 0.4588 - acc: 0.8332 - val_loss: 0.1528 - val_acc: 0.9952\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.4211 - acc: 0.8489 - val_loss: 0.1487 - val_acc: 0.9952\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.3975 - acc: 0.8493 - val_loss: 0.1475 - val_acc: 0.9952\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.2919 - acc: 0.8724 - val_loss: 0.0919 - val_acc: 0.9769\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.2201 - acc: 0.9067 - val_loss: 0.0739 - val_acc: 0.9760\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.1716 - acc: 0.9359 - val_loss: 0.0769 - val_acc: 0.9740\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.1358 - acc: 0.9514 - val_loss: 0.0790 - val_acc: 0.9683\n",
      "Epoch 8/10\n",
      " - 6s - loss: 0.1071 - acc: 0.9637 - val_loss: 0.0738 - val_acc: 0.9692\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0886 - acc: 0.9704 - val_loss: 0.0793 - val_acc: 0.9615\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0758 - acc: 0.9760 - val_loss: 0.0896 - val_acc: 0.9625\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.5764\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_7_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_3_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_3_predictions_df = pd.DataFrame(exp_3_predictions)\n",
    "exp_3_predictions_df.to_csv('exp_7_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_6_data = convote_sequences\n",
    "exp_6_labels = convote_labels\n",
    "\n",
    "add_data = ibc_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments for different models: 8 - semi-supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(exp_6_data, exp_6_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(LSTM(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 11s - loss: 0.7180 - acc: 0.4982 - val_loss: 0.6919 - val_acc: 0.5303\n",
      "Epoch 2/10\n",
      " - 7s - loss: 0.6843 - acc: 0.5465 - val_loss: 0.6643 - val_acc: 0.6145\n",
      "Epoch 3/10\n",
      " - 7s - loss: 0.6100 - acc: 0.7280 - val_loss: 0.6021 - val_acc: 0.6835\n",
      "Epoch 4/10\n",
      " - 7s - loss: 0.5050 - acc: 0.8010 - val_loss: 0.5917 - val_acc: 0.6886\n",
      "Epoch 5/10\n",
      " - 7s - loss: 0.4299 - acc: 0.8379 - val_loss: 0.5801 - val_acc: 0.7138\n",
      "Epoch 6/10\n",
      " - 7s - loss: 0.3765 - acc: 0.8596 - val_loss: 0.6064 - val_acc: 0.7054\n",
      "Epoch 7/10\n",
      " - 7s - loss: 0.3360 - acc: 0.8792 - val_loss: 0.6558 - val_acc: 0.6987\n",
      "Epoch 8/10\n",
      " - 7s - loss: 0.3096 - acc: 0.8865 - val_loss: 0.6695 - val_acc: 0.7003\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_8_lstm.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6961\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8694 samples, validate on 967 samples\n",
      "Epoch 1/10\n",
      " - 13s - loss: 0.3673 - acc: 0.8642 - val_loss: 0.2826 - val_acc: 0.9049\n",
      "Epoch 2/10\n",
      " - 11s - loss: 0.2980 - acc: 0.8952 - val_loss: 0.3159 - val_acc: 0.8873\n",
      "Epoch 3/10\n",
      " - 12s - loss: 0.2603 - acc: 0.9081 - val_loss: 0.3289 - val_acc: 0.8645\n",
      "Epoch 4/10\n",
      " - 11s - loss: 0.2405 - acc: 0.9138 - val_loss: 0.3814 - val_acc: 0.8480\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6894\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_lstm.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lstm = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(GRU(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.6940 - acc: 0.5420 - val_loss: 0.6676 - val_acc: 0.6279\n",
      "Epoch 2/10\n",
      " - 6s - loss: 0.5965 - acc: 0.7040 - val_loss: 0.5896 - val_acc: 0.6785\n",
      "Epoch 3/10\n",
      " - 6s - loss: 0.4879 - acc: 0.7768 - val_loss: 0.5516 - val_acc: 0.7222\n",
      "Epoch 4/10\n",
      " - 6s - loss: 0.4133 - acc: 0.8262 - val_loss: 0.5874 - val_acc: 0.6970\n",
      "Epoch 5/10\n",
      " - 6s - loss: 0.3685 - acc: 0.8431 - val_loss: 0.5819 - val_acc: 0.7088\n",
      "Epoch 6/10\n",
      " - 6s - loss: 0.3197 - acc: 0.8669 - val_loss: 0.6114 - val_acc: 0.7088\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='exp_8_gru.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6867\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8694 samples, validate on 967 samples\n",
      "Epoch 1/10\n",
      " - 12s - loss: 0.4031 - acc: 0.8317 - val_loss: 0.2999 - val_acc: 0.8956\n",
      "Epoch 2/10\n",
      " - 10s - loss: 0.3167 - acc: 0.8742 - val_loss: 0.2940 - val_acc: 0.8780\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.2811 - acc: 0.8905 - val_loss: 0.3029 - val_acc: 0.8811\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.2459 - acc: 0.9019 - val_loss: 0.3166 - val_acc: 0.8687\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.2226 - acc: 0.9109 - val_loss: 0.3613 - val_acc: 0.8542\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6813\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_gru.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_word_count, seq_length, input_length=seq_length))\n",
    "model.add(SimpleRNN(20, dropout=0.3, recurrent_dropout=0.3))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5341 samples, validate on 594 samples\n",
      "Epoch 1/20\n",
      " - 8s - loss: 0.7458 - acc: 0.5025 - val_loss: 0.6901 - val_acc: 0.5320\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.6969 - acc: 0.5149 - val_loss: 0.6883 - val_acc: 0.5556\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.6852 - acc: 0.5462 - val_loss: 0.6816 - val_acc: 0.5606\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.6636 - acc: 0.6087 - val_loss: 0.6627 - val_acc: 0.6145\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.5989 - acc: 0.6896 - val_loss: 0.6215 - val_acc: 0.6734\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.5249 - acc: 0.7422 - val_loss: 0.6218 - val_acc: 0.6650\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.4667 - acc: 0.7781 - val_loss: 0.6298 - val_acc: 0.6532\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.4314 - acc: 0.8021 - val_loss: 0.6489 - val_acc: 0.6414\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.3990 - acc: 0.8214 - val_loss: 0.6508 - val_acc: 0.6549\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.3532 - acc: 0.8446 - val_loss: 0.6658 - val_acc: 0.6734\n"
     ]
    }
   ],
   "source": [
    "## Fit the model\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='exp_8_rnn.h5', monitor='val_loss', save_best_only=True)]\n",
    "\n",
    "history = model.fit(x_train, y_train, validation_split=0.1, epochs=20, callbacks = callbacks, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6637\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_psuedo_labels = best_model.predict(add_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlab_labels = []\n",
    "\n",
    "for pred in add_psuedo_labels:\n",
    "    if pred > 0.5:\n",
    "        unlab_labels.append(1)\n",
    "    else:\n",
    "        unlab_labels.append(0)\n",
    "        \n",
    "unlab_labels = np.array(unlab_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.concatenate((x_train, add_data), axis = 0)\n",
    "new_y = np.concatenate((y_train, unlab_labels), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8694 samples, validate on 967 samples\n",
      "Epoch 1/10\n",
      " - 6s - loss: 0.5258 - acc: 0.7476 - val_loss: 0.4205 - val_acc: 0.8428\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.4328 - acc: 0.8077 - val_loss: 0.4048 - val_acc: 0.8108\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.3707 - acc: 0.8379 - val_loss: 0.4020 - val_acc: 0.8211\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.3357 - acc: 0.8568 - val_loss: 0.4380 - val_acc: 0.7952\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.2995 - acc: 0.8768 - val_loss: 0.4751 - val_acc: 0.7725\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.2731 - acc: 0.8862 - val_loss: 0.4844 - val_acc: 0.7746\n",
      "Epoch 7/10\n",
      " - 5s - loss: 0.2498 - acc: 0.8968 - val_loss: 0.5196 - val_acc: 0.7580\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.2331 - acc: 0.9018 - val_loss: 0.5389 - val_acc: 0.7549\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(new_x, new_y, validation_split=0.1, epochs=10, callbacks = callbacks, verbose = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6678\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('exp_8_rnn.h5')\n",
    "test_loss, test_accuracy = best_model.evaluate(x_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rnn = best_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test.reshape(len(y_test),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_4_predictions = np.concatenate((y_pred_lstm, y_pred_gru, y_pred_rnn, y_t), axis=1)\n",
    "exp_4_predictions_df = pd.DataFrame(exp_4_predictions)\n",
    "exp_4_predictions_df.to_csv('exp_8_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
